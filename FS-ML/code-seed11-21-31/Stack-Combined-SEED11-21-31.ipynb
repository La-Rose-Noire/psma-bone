{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e925f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mutual_info_score, roc_curve, auc, confusion_matrix, classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71777671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.603086\n",
      "         Iterations 7\n",
      "SUVmax - univariate logistic regression:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Label   No. Observations:                  198\n",
      "Model:                          Logit   Df Residuals:                      196\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 03 Dec 2024   Pseudo R-squ.:                  0.1294\n",
      "Time:                        18:30:40   Log-Likelihood:                -119.41\n",
      "converged:                       True   LL-Null:                       -137.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.574e-09\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0732      0.169      0.432      0.666      -0.259       0.405\n",
      "SUVmax         1.3164      0.308      4.270      0.000       0.712       1.921\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.603086\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.603086\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "# read data (Baseline)\n",
    "train_data_Baseline = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\Baseline\\6-4ADASYN-11\\original\\train.csv')\n",
    "test_data_Baseline = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\Baseline\\6-4ADASYN-11\\original\\test.csv')\n",
    "\n",
    "# Selector --- univariate logistic regression\n",
    "significant_features_Baseline = []\n",
    "\n",
    "def perform_single_factor_analyses_and_select_features(train_df):\n",
    "    global significant_features_Baseline\n",
    "    significant_features_Baseline = [] \n",
    "    num_features = len(train_df.columns) - 1 \n",
    "    for i in range(num_features):\n",
    "        feature_name = train_df.columns[i+1]\n",
    "        X = train_df[[feature_name]]\n",
    "        y = train_df['Label']\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.Logit(y, X).fit()\n",
    "        print(f\"{feature_name} - univariate logistic regression:\")\n",
    "        print(model.summary())\n",
    "        \n",
    "        if model.pvalues[1] < 0.05:\n",
    "            significant_features_Baseline.append(feature_name)\n",
    "            \n",
    "    return significant_features_Baseline\n",
    "\n",
    "selected_features_Baseline = perform_single_factor_analyses_and_select_features(train_data_Baseline)\n",
    "\n",
    "# Classifier --- multivariate logistic regression\n",
    "def build_multi_factor_model_Baseline(train_data_Baseline, test_data_Baseline, selected_features_Baseline):\n",
    "    X_train_Baseline = train_data_Baseline[selected_features_Baseline]\n",
    "    y_train_Baseline = train_data_Baseline['Label']\n",
    "    X_test_Baseline = test_data_Baseline[selected_features_Baseline]\n",
    "    y_test_Baseline = test_data_Baseline['Label']\n",
    "    \n",
    "    X_train_sm_Baseline = sm.add_constant(X_train_Baseline)\n",
    "    X_test_sm_Baseline = sm.add_constant(X_test_Baseline)\n",
    "    \n",
    "    model_Baseline = sm.Logit(y_train_Baseline, X_train_sm_Baseline)\n",
    "    result_Baseline = model_Baseline.fit()\n",
    "    \n",
    "    y_pred_probs_train_Baseline = result_Baseline.predict(X_train_sm_Baseline)  \n",
    "    y_pred_probs_test_Baseline = result_Baseline.predict(X_test_sm_Baseline)  \n",
    "    \n",
    "    y_pred_train_Baseline = (y_pred_probs_train_Baseline > 0.5).astype(int)\n",
    "    y_pred_test_Baseline = (y_pred_probs_test_Baseline > 0.5).astype(int)\n",
    "    \n",
    "    return y_pred_probs_train_Baseline, y_pred_probs_test_Baseline\n",
    "    \n",
    "build_multi_factor_model_Baseline(train_data_Baseline, test_data_Baseline, selected_features_Baseline)\n",
    "\n",
    "y_pred_probs_train_Baseline, y_pred_probs_test_Baseline = build_multi_factor_model_Baseline(train_data_Baseline, test_data_Baseline, selected_features_Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bfc4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One example of dual-modality PET-CT stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "# Read data (CT)\n",
    "train_data_CT = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_CT_bin50\\6-4ADASYN-11\\train.csv')\n",
    "test_data_CT = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_CT_bin50\\6-4ADASYN-11\\test.csv')\n",
    "\n",
    "X_train_CT = train_data_CT.iloc[:, 1:]  \n",
    "y_train_CT = train_data_CT.iloc[:, 0]   \n",
    "X_test_CT = test_data_CT.iloc[:, 1:]  \n",
    "y_test_CT = test_data_CT.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbaf919",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "# Read data (PET)\n",
    "train_data_PET = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_PET1_bin0.25\\6-4ADASYN-11\\original\\train.csv')\n",
    "test_data_PET = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_PET1_bin0.25\\6-4ADASYN-11\\original\\test.csv')\n",
    "\n",
    "X_train_PET = train_data_PET.iloc[:, 1:]  \n",
    "y_train_PET = train_data_PET.iloc[:, 0]   \n",
    "X_test_PET = test_data_PET.iloc[:, 1:]   \n",
    "y_test_PET = test_data_PET.iloc[:, 0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a393ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': False, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Sensitivity (Cross-Validation_CT): 0.8438\n",
      "Specificity (Cross-Validation_CT): 0.7255\n",
      "PPV (Cross-Validation_CT): 0.7431\n",
      "NPV (Cross-Validation_CT): 0.8315\n",
      "Precision (Cross-Validation_CT): 0.7431\n",
      "Recall (Cross-Validation_CT): 0.8438\n",
      "F1 Score (Cross-Validation_CT): 0.7902\n",
      "Train Accuracy (Cross-Validation_CT): 0.7783\n",
      "Sensitivity (Test_CT): 0.5667\n",
      "Specificity (Test_CT): 0.8625\n",
      "PPV (Test_CT): 0.6071\n",
      "NPV (Test_CT): 0.8415\n",
      "Precision (Test_CT): 0.6071\n",
      "Recall (Test_CT): 0.5667\n",
      "F1 Score (Test_CT): 0.5862\n",
      "Test Accuracy_CT: 0.7818\n",
      "Cross-Validation AUC_CT: 0.8586 (95% CI: 0.8070, 0.9102)\n",
      "Test AUC_CT: 0.8266 (95% CI: 0.7457, 0.9075)\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality PET-CT stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "#Classifier (CT) --- Random Forest\n",
    "np.random.seed(0)\n",
    "param_grid_CT = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],    \n",
    "    'bootstrap': [True, False]        \n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "grid_search_CT = GridSearchCV(estimator=rf, param_grid=param_grid_CT, cv=5, scoring='accuracy')\n",
    "grid_search_CT.fit(X_train_CT, y_train_CT)\n",
    "print(\"Best parameters:\", grid_search_CT.best_params_)\n",
    "best_model_CT = grid_search_CT.best_estimator_\n",
    "\n",
    "y_train_pred_cv_CT = cross_val_predict(best_model_CT, X_train_CT, y_train_CT, cv=5)\n",
    "y_train_pred_proba_cv_CT = cross_val_predict(best_model_CT, X_train_CT, y_train_CT, cv=5, method='predict_proba')[:, 1]\n",
    "train_precision_cv_CT, train_recall_cv_CT, train_f1_cv_CT, _ = precision_recall_fscore_support(y_train_CT, y_train_pred_cv_CT, average='binary')\n",
    "y_test_pred_CT = best_model_CT.predict(X_test_CT)\n",
    "y_test_pred_proba_CT = best_model_CT.predict_proba(X_test_CT)[:, 1]\n",
    "test_precision_CT, test_recall_CT, test_f1_CT, _ = precision_recall_fscore_support(y_test_CT, y_test_pred_CT, average='binary')\n",
    "\n",
    "train_accuracy_cv_CT = cross_val_score(best_model_CT, X_train_CT, y_train_CT, cv=5, scoring='accuracy').mean()\n",
    "test_accuracy_CT = accuracy_score(y_test_CT, y_test_pred_CT)\n",
    "conf_mat_train_cv_CT = confusion_matrix(y_train_CT, y_train_pred_cv_CT)\n",
    "conf_mat_test_CT = confusion_matrix(y_test_CT, y_test_pred_CT)\n",
    "sensitivity_train_CT = conf_mat_train_cv_CT[1, 1] / (conf_mat_train_cv_CT[1, 1] + conf_mat_train_cv_CT[1, 0])  # TP / (TP + FN)\n",
    "sensitivity_test_CT = conf_mat_test_CT[1, 1] / (conf_mat_test_CT[1, 1] + conf_mat_test_CT[1, 0])  # TP / (TP + FN)\n",
    "specificity_train_CT = conf_mat_train_cv_CT[0, 0] / (conf_mat_train_cv_CT[0, 0] + conf_mat_train_cv_CT[0, 1])\n",
    "specificity_test_CT = conf_mat_test_CT[0, 0] / (conf_mat_test_CT[0, 0] + conf_mat_test_CT[0, 1])\n",
    "ppv_train_CT = conf_mat_train_cv_CT[1, 1] / (conf_mat_train_cv_CT[1, 1] + conf_mat_train_cv_CT[0, 1])\n",
    "npv_train_CT = conf_mat_train_cv_CT[0, 0] / (conf_mat_train_cv_CT[0, 0] + conf_mat_train_cv_CT[1, 0])\n",
    "ppv_test_CT = conf_mat_test_CT[1, 1] / (conf_mat_test_CT[1, 1] + conf_mat_test_CT[0, 1])\n",
    "npv_test_CT = conf_mat_test_CT[0, 0] / (conf_mat_test_CT[0, 0] + conf_mat_test_CT[1, 0])\n",
    "train_precision_CT = precision_score(y_train_CT, y_train_pred_cv_CT)\n",
    "test_precision_CT = precision_score(y_test_CT, y_test_pred_CT)\n",
    "train_recall_CT = recall_score(y_train_CT, y_train_pred_cv_CT)\n",
    "test_recall_CT = recall_score(y_test_CT, y_test_pred_CT)\n",
    "train_f1_CT = f1_score(y_train_CT, y_train_pred_cv_CT)\n",
    "test_f1_CT = f1_score(y_test_CT, y_test_pred_CT)\n",
    "print(f\"Sensitivity (Cross-Validation_CT): {sensitivity_train_CT:.4f}\")\n",
    "print(f\"Specificity (Cross-Validation_CT): {specificity_train_CT:.4f}\")\n",
    "print(f\"PPV (Cross-Validation_CT): {ppv_train_CT:.4f}\")\n",
    "print(f\"NPV (Cross-Validation_CT): {npv_train_CT:.4f}\")\n",
    "print(f\"Precision (Cross-Validation_CT): {train_precision_CT:.4f}\")\n",
    "print(f\"Recall (Cross-Validation_CT): {train_recall_CT:.4f}\")\n",
    "print(f\"F1 Score (Cross-Validation_CT): {train_f1_CT:.4f}\")\n",
    "print(f\"Train Accuracy (Cross-Validation_CT): {train_accuracy_cv_CT:.4f}\")\n",
    "print(f\"Sensitivity (Test_CT): {sensitivity_test_CT:.4f}\")\n",
    "print(f\"Specificity (Test_CT): {specificity_test_CT:.4f}\")\n",
    "print(f\"PPV (Test_CT): {ppv_test_CT:.4f}\")\n",
    "print(f\"NPV (Test_CT): {npv_test_CT:.4f}\")\n",
    "print(f\"Precision (Test_CT): {test_precision_CT:.4f}\")\n",
    "print(f\"Recall (Test_CT): {test_recall_CT:.4f}\")\n",
    "print(f\"F1 Score (Test_CT): {test_f1_CT:.4f}\")\n",
    "print(f\"Test Accuracy_CT: {test_accuracy_CT:.4f}\")\n",
    "\n",
    "fpr_train_CT, tpr_train_CT, _ = roc_curve(y_train_CT, y_train_pred_proba_cv_CT)\n",
    "fpr_test_CT, tpr_test_CT, _ = roc_curve(y_test_CT, y_test_pred_proba_CT)\n",
    "np.random.seed(0)\n",
    "def bootstrap_roc_auc(y_true, y_scores, n_bootstraps=1000):\n",
    "    auc_scores = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true), size=len(y_true))\n",
    "        auc_scores[i] = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "    return auc_scores\n",
    "\n",
    "auc_scores_train_CT = bootstrap_roc_auc(y_train_CT, y_train_pred_proba_cv_CT)\n",
    "auc_train_mean_CT = np.mean(auc_scores_train_CT)\n",
    "auc_train_std_CT = np.std(auc_scores_train_CT)\n",
    "auc_train_lower_CT = norm.ppf(0.025, loc=auc_train_mean_CT, scale=auc_train_std_CT)\n",
    "auc_train_upper_CT = norm.ppf(0.975, loc=auc_train_mean_CT, scale=auc_train_std_CT)\n",
    "print(f\"Cross-Validation AUC_CT: {auc_train_mean_CT:.4f} (95% CI: {auc_train_lower_CT:.4f}, {auc_train_upper_CT:.4f})\")\n",
    "\n",
    "auc_scores_test_CT = bootstrap_roc_auc(y_test_CT, y_test_pred_proba_CT)\n",
    "auc_test_mean_CT = np.mean(auc_scores_test_CT)\n",
    "auc_test_std_CT = np.std(auc_scores_test_CT)\n",
    "auc_test_lower_CT = norm.ppf(0.025, loc=auc_test_mean_CT, scale=auc_test_std_CT)\n",
    "auc_test_upper_CT = norm.ppf(0.975, loc=auc_test_mean_CT, scale=auc_test_std_CT)\n",
    "print(f\"Test AUC_CT: {auc_test_mean_CT:.4f} (95% CI: {auc_test_lower_CT:.4f}, {auc_test_upper_CT:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a64ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "Sensitivity (Cross-Validation_PET): 0.6979\n",
      "Specificity (Cross-Validation_PET): 0.7745\n",
      "PPV (Cross-Validation_PET): 0.7444\n",
      "NPV (Cross-Validation_PET): 0.7315\n",
      "Precision (Cross-Validation_PET): 0.7444\n",
      "Recall (Cross-Validation_PET): 0.6979\n",
      "F1 Score (Cross-Validation_PET): 0.7204\n",
      "Train Accuracy (Cross-Validation_PET): 0.7374\n",
      "Sensitivity (Test_PET): 0.7667\n",
      "Specificity (Test_PET): 0.7875\n",
      "PPV (Test_PET): 0.5750\n",
      "NPV (Test_PET): 0.9000\n",
      "Precision (Test_PET): 0.5750\n",
      "Recall (Test_PET): 0.7667\n",
      "F1 Score (Test_PET): 0.6571\n",
      "Test Accuracy_PET: 0.7818\n",
      "Cross-Validation AUC_PET: 0.7888 (95% CI: 0.7240, 0.8536)\n",
      "Test AUC_PET: 0.8427 (95% CI: 0.7666, 0.9188)\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality PET-CT stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "#Classifier (PET) --- Logistic Regression\n",
    "np.random.seed(0)\n",
    "param_grid_PET = {\n",
    "    'C': [0.1, 1.0, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [1000],\n",
    "    'tol': [1e-4]\n",
    "}\n",
    "logistic = LogisticRegression()\n",
    "grid_search_PET = GridSearchCV(estimator=logistic, param_grid=param_grid_PET, cv=5, scoring='accuracy')\n",
    "grid_search_PET.fit(X_train_PET, y_train_PET)\n",
    "print(\"Best parameters:\", grid_search_PET.best_params_)\n",
    "best_model_PET = grid_search_PET.best_estimator_\n",
    "\n",
    "y_train_pred_cv_PET = cross_val_predict(best_model_PET, X_train_PET, y_train_PET, cv=5)\n",
    "y_train_pred_proba_cv_PET = cross_val_predict(best_model_PET, X_train_PET, y_train_PET, cv=5, method='predict_proba')[:, 1]\n",
    "train_precision_cv_PET, train_recall_cv_PET, train_f1_cv_PET, _ = precision_recall_fscore_support(y_train_PET, y_train_pred_cv_PET, average='binary')\n",
    "y_test_pred_PET = best_model_PET.predict(X_test_PET)\n",
    "y_test_pred_proba_PET = best_model_PET.predict_proba(X_test_PET)[:, 1]\n",
    "test_precision_PET, test_recall_PET, test_f1_PET, _ = precision_recall_fscore_support(y_test_PET, y_test_pred_PET, average='binary')\n",
    "\n",
    "train_accuracy_cv_PET = cross_val_score(best_model_PET, X_train_PET, y_train_PET, cv=5, scoring='accuracy').mean()\n",
    "test_accuracy_PET = accuracy_score(y_test_PET, y_test_pred_PET)\n",
    "conf_mat_train_cv_PET = confusion_matrix(y_train_PET, y_train_pred_cv_PET)\n",
    "conf_mat_test_PET = confusion_matrix(y_test_PET, y_test_pred_PET)\n",
    "sensitivity_train_PET = conf_mat_train_cv_PET[1, 1] / (conf_mat_train_cv_PET[1, 1] + conf_mat_train_cv_PET[1, 0])  # TP / (TP + FN)\n",
    "sensitivity_test_PET = conf_mat_test_PET[1, 1] / (conf_mat_test_PET[1, 1] + conf_mat_test_PET[1, 0])  # TP / (TP + FN)\n",
    "specificity_train_PET = conf_mat_train_cv_PET[0, 0] / (conf_mat_train_cv_PET[0, 0] + conf_mat_train_cv_PET[0, 1])\n",
    "specificity_test_PET = conf_mat_test_PET[0, 0] / (conf_mat_test_PET[0, 0] + conf_mat_test_PET[0, 1])\n",
    "ppv_train_PET = conf_mat_train_cv_PET[1, 1] / (conf_mat_train_cv_PET[1, 1] + conf_mat_train_cv_PET[0, 1])\n",
    "npv_train_PET = conf_mat_train_cv_PET[0, 0] / (conf_mat_train_cv_PET[0, 0] + conf_mat_train_cv_PET[1, 0])\n",
    "ppv_test_PET = conf_mat_test_PET[1, 1] / (conf_mat_test_PET[1, 1] + conf_mat_test_PET[0, 1])\n",
    "npv_test_PET = conf_mat_test_PET[0, 0] / (conf_mat_test_PET[0, 0] + conf_mat_test_PET[1, 0])\n",
    "train_precision_PET = precision_score(y_train_PET, y_train_pred_cv_PET)\n",
    "test_precision_PET = precision_score(y_test_PET, y_test_pred_PET)\n",
    "train_recall_PET = recall_score(y_train_PET, y_train_pred_cv_PET)\n",
    "test_recall_PET = recall_score(y_test_PET, y_test_pred_PET)\n",
    "train_f1_PET = f1_score(y_train_PET, y_train_pred_cv_PET)\n",
    "test_f1_PET = f1_score(y_test_PET, y_test_pred_PET)\n",
    "print(f\"Sensitivity (Cross-Validation_PET): {sensitivity_train_PET:.4f}\")\n",
    "print(f\"Specificity (Cross-Validation_PET): {specificity_train_PET:.4f}\")\n",
    "print(f\"PPV (Cross-Validation_PET): {ppv_train_PET:.4f}\")\n",
    "print(f\"NPV (Cross-Validation_PET): {npv_train_PET:.4f}\")\n",
    "print(f\"Precision (Cross-Validation_PET): {train_precision_PET:.4f}\")\n",
    "print(f\"Recall (Cross-Validation_PET): {train_recall_PET:.4f}\")\n",
    "print(f\"F1 Score (Cross-Validation_PET): {train_f1_PET:.4f}\")\n",
    "print(f\"Train Accuracy (Cross-Validation_PET): {train_accuracy_cv_PET:.4f}\")\n",
    "print(f\"Sensitivity (Test_PET): {sensitivity_test_PET:.4f}\")\n",
    "print(f\"Specificity (Test_PET): {specificity_test_PET:.4f}\")\n",
    "print(f\"PPV (Test_PET): {ppv_test_PET:.4f}\")\n",
    "print(f\"NPV (Test_PET): {npv_test_PET:.4f}\")\n",
    "print(f\"Precision (Test_PET): {test_precision_PET:.4f}\")\n",
    "print(f\"Recall (Test_PET): {test_recall_PET:.4f}\")\n",
    "print(f\"F1 Score (Test_PET): {test_f1_PET:.4f}\")\n",
    "print(f\"Test Accuracy_PET: {test_accuracy_PET:.4f}\")\n",
    "\n",
    "fpr_train_PET, tpr_train_PET, _ = roc_curve(y_train_PET, y_train_pred_proba_cv_PET)\n",
    "fpr_test_PET, tpr_test_PET, _ = roc_curve(y_test_PET, y_test_pred_proba_PET)\n",
    "np.random.seed(0)\n",
    "def bootstrap_roc_auc(y_true, y_scores, n_bootstraps=1000):\n",
    "    auc_scores = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true), size=len(y_true))\n",
    "        auc_scores[i] = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "    return auc_scores\n",
    "\n",
    "auc_scores_train_PET = bootstrap_roc_auc(y_train_PET, y_train_pred_proba_cv_PET)\n",
    "auc_train_mean_PET = np.mean(auc_scores_train_PET)\n",
    "auc_train_std_PET = np.std(auc_scores_train_PET)\n",
    "auc_train_lower_PET = norm.ppf(0.025, loc=auc_train_mean_PET, scale=auc_train_std_PET)\n",
    "auc_train_upper_PET = norm.ppf(0.975, loc=auc_train_mean_PET, scale=auc_train_std_PET)\n",
    "print(f\"Cross-Validation AUC_PET: {auc_train_mean_PET:.4f} (95% CI: {auc_train_lower_PET:.4f}, {auc_train_upper_PET:.4f})\")\n",
    "\n",
    "auc_scores_test_PET = bootstrap_roc_auc(y_test_PET, y_test_pred_proba_PET)\n",
    "auc_test_mean_PET = np.mean(auc_scores_test_PET)\n",
    "auc_test_std_PET = np.std(auc_scores_test_PET)\n",
    "auc_test_lower_PET = norm.ppf(0.025, loc=auc_test_mean_PET, scale=auc_test_std_PET)\n",
    "auc_test_upper_PET = norm.ppf(0.975, loc=auc_test_mean_PET, scale=auc_test_std_PET)\n",
    "print(f\"Test AUC_PET: {auc_test_mean_PET:.4f} (95% CI: {auc_test_lower_PET:.4f}, {auc_test_upper_PET:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f83b25eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression Meta-learner: {'C': 1.0, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "Sensitivity (Cross-Validation Meta-learner): 0.8542\n",
      "Specificity (Cross-Validation Meta-learner): 0.8039\n",
      "PPV (Cross-Validation Meta-learner): 0.8039\n",
      "NPV (Cross-Validation Meta-learner): 0.8542\n",
      "Precision (Cross-Validation Meta-learner): 0.8039\n",
      "Recall (Cross-Validation Meta-learner): 0.8542\n",
      "F1 Score (Cross-Validation Meta-learner): 0.8283\n",
      "Train Accuracy (Cross-Validation  Meta-learner): 0.8288\n",
      "Sensitivity (Test Meta-learner): 0.6333\n",
      "Specificity (Test Meta-learner): 0.8875\n",
      "PPV (Test Meta-learner): 0.6786\n",
      "NPV (Test Meta-learner): 0.8659\n",
      "Precision (Test Meta-learner): 0.6786\n",
      "Recall (Test Meta-learner): 0.6333\n",
      "F1 Score (Test Meta-learner): 0.6552\n",
      "Test Accuracy (Test Meta-learner): 0.8182\n",
      "Meta-learner Cross-Validation AUC: 0.8926 (95% CI: 0.8484, 0.9369)\n",
      "Meta-learner Test AUC: 0.8763 (95% CI: 0.8081, 0.9445)\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "#Classifier (Meta) --- Logistic Regression\n",
    "X_train_meta_features = np.column_stack([\n",
    "    y_pred_probs_train_Baseline,  \n",
    "    y_train_pred_proba_cv_CT,      \n",
    "    y_train_pred_proba_cv_PET    \n",
    "])\n",
    "\n",
    "X_test_meta_features = np.column_stack([\n",
    "    y_pred_probs_test_Baseline,   \n",
    "    y_test_pred_proba_CT,         \n",
    "    y_test_pred_proba_PET         \n",
    "])\n",
    "\n",
    "np.random.seed(0)\n",
    "lr = LogisticRegression()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [1000],\n",
    "    'tol': [1e-4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_meta_features, y_train_CT)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters for Logistic Regression Meta-learner:\", best_params)\n",
    "\n",
    "best_meta_model = grid_search.best_estimator_\n",
    "y_train_meta_pred = cross_val_predict(best_meta_model, X_train_meta_features, y_train_CT, cv=5)\n",
    "y_test_meta_pred = best_meta_model.predict(X_test_meta_features)\n",
    "y_train_meta_pred_proba = cross_val_predict(best_meta_model, X_train_meta_features, y_train_CT, cv=5, method='predict_proba')[:, 1]\n",
    "y_test_meta_pred_proba = best_meta_model.predict_proba(X_test_meta_features)[:, 1]\n",
    "\n",
    "train_accuracy_meta = cross_val_score(best_meta_model, X_train_meta_features, y_train_CT, cv=5, scoring='accuracy').mean()\n",
    "test_accuracy_meta = accuracy_score(y_test_CT, y_test_meta_pred)\n",
    "train_precision_meta, train_recall_meta, train_f1_meta, _ = precision_recall_fscore_support(y_train_CT, y_train_meta_pred, average='binary')\n",
    "test_precision_meta, test_recall_meta, test_f1_meta, _ = precision_recall_fscore_support(y_test_CT, y_test_meta_pred, average='binary')\n",
    "\n",
    "def calculate_additional_metrics(y_true, y_pred, y_proba):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])  # TP / (TP + FN)\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # TN / (TN + FP)\n",
    "    ppv = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])  # TP / (TP + FP)\n",
    "    npv = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[1, 0])  # TN / (TN + FN)\n",
    "    return sensitivity, specificity, ppv, npv, conf_matrix\n",
    "\n",
    "sensitivity_train_meta, train_specificity, train_ppv, train_npv, conf_mat_train_meta = calculate_additional_metrics(y_train_CT, y_train_meta_pred, y_train_meta_pred_proba)\n",
    "sensitivity_test_meta, test_specificity, test_ppv, test_npv, conf_mat_test_meta = calculate_additional_metrics(y_test_CT, y_test_meta_pred, y_test_meta_pred_proba)\n",
    "\n",
    "print(f\"Sensitivity (Cross-Validation Meta-learner): {sensitivity_train_meta:.4f}\")\n",
    "print(f\"Specificity (Cross-Validation Meta-learner): {train_specificity:.4f}\")\n",
    "print(f\"PPV (Cross-Validation Meta-learner): {train_ppv:.4f}\")\n",
    "print(f\"NPV (Cross-Validation Meta-learner): {train_npv:.4f}\")\n",
    "print(f\"Precision (Cross-Validation Meta-learner): {train_precision_meta:.4f}\")\n",
    "print(f\"Recall (Cross-Validation Meta-learner): {train_recall_meta:.4f}\")\n",
    "print(f\"F1 Score (Cross-Validation Meta-learner): {train_f1_meta:.4f}\")\n",
    "print(f\"Train Accuracy (Cross-Validation  Meta-learner): {train_accuracy_meta:.4f}\")\n",
    "print(f\"Sensitivity (Test Meta-learner): {sensitivity_test_meta:.4f}\")\n",
    "print(f\"Specificity (Test Meta-learner): {test_specificity:.4f}\")\n",
    "print(f\"PPV (Test Meta-learner): {test_ppv:.4f}\")\n",
    "print(f\"NPV (Test Meta-learner): {test_npv:.4f}\")\n",
    "print(f\"Precision (Test Meta-learner): {test_precision_meta:.4f}\")\n",
    "print(f\"Recall (Test Meta-learner): {test_recall_meta:.4f}\")\n",
    "print(f\"F1 Score (Test Meta-learner): {test_f1_meta:.4f}\")\n",
    "print(f\"Test Accuracy (Test Meta-learner): {test_accuracy_meta:.4f}\")\n",
    "\n",
    "np.random.seed(0)\n",
    "def bootstrap_roc_auc(y_true, y_scores, n_bootstraps=1000):\n",
    "    auc_scores = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true), size=len(y_true))\n",
    "        auc_scores[i] = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "    return auc_scores\n",
    "\n",
    "fpr_train_meta, tpr_train_meta, _ = roc_curve(y_train_CT, y_train_meta_pred_proba)\n",
    "fpr_test_meta, tpr_test_meta, _ = roc_curve(y_test_CT, y_test_meta_pred_proba)\n",
    "auc_scores_train_meta = bootstrap_roc_auc(y_train_CT, y_train_meta_pred_proba)\n",
    "auc_scores_test_meta = bootstrap_roc_auc(y_test_CT, y_test_meta_pred_proba)\n",
    "auc_train_mean_meta = np.mean(auc_scores_train_meta)\n",
    "auc_train_std_meta = np.std(auc_scores_train_meta)\n",
    "auc_test_mean_meta = np.mean(auc_scores_test_meta)\n",
    "auc_test_std_meta = np.std(auc_scores_test_meta)\n",
    "auc_train_lower_meta = norm.ppf(0.025, loc=auc_train_mean_meta, scale=auc_train_std_meta)\n",
    "auc_train_upper_meta = norm.ppf(0.975, loc=auc_train_mean_meta, scale=auc_train_std_meta)\n",
    "auc_test_lower_meta = norm.ppf(0.025, loc=auc_test_mean_meta, scale=auc_test_std_meta)\n",
    "auc_test_upper_meta = norm.ppf(0.975, loc=auc_test_mean_meta, scale=auc_test_std_meta)\n",
    "print(f\"Meta-learner Cross-Validation AUC: {auc_train_mean_meta:.4f} (95% CI: {auc_train_lower_meta:.4f}, {auc_train_upper_meta:.4f})\")\n",
    "print(f\"Meta-learner Test AUC: {auc_test_mean_meta:.4f} (95% CI: {auc_test_lower_meta:.4f}, {auc_test_upper_meta:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699c31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (python3.7)",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
