{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978ecffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features names: ['wavelet.LLH_glszm_GrayLevelVariance', 'log.sigma.1.mm.3D_glcm_Correlation', 'log.sigma.2.mm.3D_glrlm_LowGrayLevelRunEmphasis', 'log.sigma.1.mm.3D_glcm_Imc1', 'wavelet.HLL_glszm_ZonePercentage', 'log.sigma.3.mm.3D_firstorder_Skewness', 'wavelet.LHL_glcm_Correlation', 'wavelet.LLH_glcm_Correlation', 'wavelet.HLH_glcm_InverseVariance', 'log.sigma.3.mm.3D_glszm_SmallAreaEmphasis']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mutual_info_score,  roc_curve, auc, confusion_matrix, classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Read data\n",
    "#file path: CT --- RFs_CT_bin50\\6-4ADASYN-1; PET (original) --- RFs_PET1_bin0.25\\6-4ADASYN-1\\original; \n",
    "#           PET (pre-Combat or Limma) --- RFs_PET1_bin0.25\\6-4ADASYN-1\\pre-Combat or Limma; PET (standardized) --- RFs_PET2_bin0.05\\6-4ADASYN-1; \n",
    "train_data = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_PET1_bin0.25\\6-4ADASYN-1\\pre-Combat\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_PET1_bin0.25\\6-4ADASYN-1\\pre-Combat\\test.csv')\n",
    "\n",
    "X_train = train_data.iloc[:, 1:] \n",
    "y_train = train_data.iloc[:, 0]  \n",
    "X_test = test_data.iloc[:, 1:]   \n",
    "y_test = test_data.iloc[:, 0]\n",
    "\n",
    "# Feature Selector ---- JMIM\n",
    "def entropy(hist):\n",
    "    pk = hist / hist.sum()\n",
    "    return -np.sum(pk[pk > 0] * np.log2(pk[pk > 0]))\n",
    "\n",
    "def JMIM_single_feature(X, Y):\n",
    "    X = np.asarray(X).ravel()\n",
    "    Y = np.asarray(Y).ravel()\n",
    "    combined = np.concatenate((X, Y))\n",
    "    thresh = np.percentile(combined, 50)  \n",
    "    max_JMIM = 0\n",
    "    \n",
    "    for threshold in np.linspace(thresh, np.max(X), num=100):\n",
    "        X_b = (X < threshold).astype(int)\n",
    "        Y_b = (Y < threshold).astype(int)\n",
    "        JMIM = mutual_info_score(X_b, Y_b)\n",
    "        if JMIM > max_JMIM:\n",
    "            max_JMIM = JMIM\n",
    "    return max_JMIM\n",
    "\n",
    "def jmim_feature_selection(X, y, k):\n",
    "    selected_features = []\n",
    "    remaining_features = list(range(X.shape[1]))\n",
    "\n",
    "    while len(selected_features) < k:\n",
    "        max_jmim = 0\n",
    "        best_feature_idx = None\n",
    "\n",
    "        for i in remaining_features:\n",
    "            jmim = JMIM_single_feature(X.iloc[:, i], y)\n",
    "            if jmim > max_jmim:\n",
    "                max_jmim = jmim\n",
    "                best_feature_idx = i\n",
    "\n",
    "        if best_feature_idx is not None:\n",
    "            selected_features.append(best_feature_idx)\n",
    "            remaining_features.remove(best_feature_idx)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "selected_feature_indices = jmim_feature_selection(X_train, y_train, 10)\n",
    "selected_features = [X_train.columns[i] for i in selected_feature_indices]\n",
    "print(\"Selected features names:\", selected_features)\n",
    "X_train_selected_top_ten = X_train[selected_features]\n",
    "X_test_selected_top_ten = X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ddb16e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'algorithm': 'auto', 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Sensitivity (Cross-Validation): 0.9072\n",
      "Specificity (Cross-Validation): 0.8953\n",
      "PPV (Cross-Validation): 0.7273\n",
      "NPV (Cross-Validation): 0.8953\n",
      "Precision (Cross-Validation): 0.7273\n",
      "Recall (Cross-Validation): 0.9072\n",
      "F1 Score (Cross-Validation): 0.8073\n",
      "Train Accuracy (Cross-Validation): 0.7969\n",
      "Sensitivity (Test): 0.6053\n",
      "Specificity (Test): 0.7692\n",
      "PPV (Test): 0.5111\n",
      "NPV (Test): 0.7692\n",
      "Precision (Test): 0.5111\n",
      "Recall (Test): 0.6053\n",
      "F1 Score (Test): 0.5542\n",
      "Test Accuracy: 0.6636\n",
      "Cross-Validation AUC: 0.8040 (95% CI: 0.7526, 0.8554)\n",
      "Test AUC: 0.6478 (95% CI: 0.5564, 0.7391)\n"
     ]
    }
   ],
   "source": [
    "#Classifier --- K-NearestNeighbor\n",
    "np.random.seed(0)\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 31)),\n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],  \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']  \n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_selected_top_ten, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_train_pred_cv = cross_val_predict(best_model, X_train_selected_top_ten, y_train, cv=5)\n",
    "y_train_pred_proba_cv = cross_val_predict(best_model, X_train_selected_top_ten, y_train, cv=5, method='predict_proba')[:, 1]\n",
    "train_precision_cv, train_recall_cv, train_f1_cv, _ = precision_recall_fscore_support(y_train, y_train_pred_cv, average='binary')\n",
    "y_test_pred = best_model.predict(X_test_selected_top_ten)\n",
    "y_test_pred_proba = best_model.predict_proba(X_test_selected_top_ten)[:, 1]\n",
    "test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, y_test_pred, average='binary')\n",
    "\n",
    "train_accuracy_cv = cross_val_score(best_model, X_train_selected_top_ten, y_train, cv=5, scoring='accuracy').mean()\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "conf_mat_train_cv = confusion_matrix(y_train, y_train_pred_cv)\n",
    "conf_mat_test = confusion_matrix(y_test, y_test_pred)\n",
    "sensitivity_train = conf_mat_train_cv[1, 1] / (conf_mat_train_cv[1, 1] + conf_mat_train_cv[1, 0])  # TP / (TP + FN)\n",
    "sensitivity_test = conf_mat_test[1, 1] / (conf_mat_test[1, 1] + conf_mat_test[1, 0])  # TP / (TP + FN)\n",
    "specificity_train = conf_mat_train_cv[0, 0] / (conf_mat_train_cv[0, 0] + conf_mat_train_cv[1, 0])\n",
    "specificity_test = conf_mat_test[0, 0] / (conf_mat_test[0, 0] + conf_mat_test[1, 0])\n",
    "ppv_train = conf_mat_train_cv[1, 1] / (conf_mat_train_cv[1, 1] + conf_mat_train_cv[0, 1])\n",
    "npv_train = conf_mat_train_cv[0, 0] / (conf_mat_train_cv[0, 0] + conf_mat_train_cv[1, 0])\n",
    "ppv_test = conf_mat_test[1, 1] / (conf_mat_test[1, 1] + conf_mat_test[0, 1])\n",
    "npv_test = conf_mat_test[0, 0] / (conf_mat_test[0, 0] + conf_mat_test[1, 0])\n",
    "train_precision = precision_score(y_train, y_train_pred_cv)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred_cv)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred_cv)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "print(f\"Sensitivity (Cross-Validation): {sensitivity_train:.4f}\")\n",
    "print(f\"Specificity (Cross-Validation): {specificity_train:.4f}\")\n",
    "print(f\"PPV (Cross-Validation): {ppv_train:.4f}\")\n",
    "print(f\"NPV (Cross-Validation): {npv_train:.4f}\")\n",
    "print(f\"Precision (Cross-Validation): {train_precision:.4f}\")\n",
    "print(f\"Recall (Cross-Validation): {train_recall:.4f}\")\n",
    "print(f\"F1 Score (Cross-Validation): {train_f1:.4f}\")\n",
    "print(f\"Train Accuracy (Cross-Validation): {train_accuracy_cv:.4f}\")\n",
    "print(f\"Sensitivity (Test): {sensitivity_test:.4f}\")\n",
    "print(f\"Specificity (Test): {specificity_test:.4f}\")\n",
    "print(f\"PPV (Test): {ppv_test:.4f}\")\n",
    "print(f\"NPV (Test): {npv_test:.4f}\")\n",
    "print(f\"Precision (Test): {test_precision:.4f}\")\n",
    "print(f\"Recall (Test): {test_recall:.4f}\")\n",
    "print(f\"F1 Score (Test): {test_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba_cv)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_proba)\n",
    "np.random.seed(0)\n",
    "def bootstrap_roc_auc(y_true, y_scores, n_bootstraps=1000):\n",
    "    auc_scores = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true), size=len(y_true))\n",
    "        auc_scores[i] = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "    return auc_scores\n",
    "\n",
    "auc_scores_train = bootstrap_roc_auc(y_train, y_train_pred_proba_cv)\n",
    "auc_train_mean = np.mean(auc_scores_train)\n",
    "auc_train_std = np.std(auc_scores_train)\n",
    "auc_train_lower = norm.ppf(0.025, loc=auc_train_mean, scale=auc_train_std)\n",
    "auc_train_upper = norm.ppf(0.975, loc=auc_train_mean, scale=auc_train_std)\n",
    "print(f\"Cross-Validation AUC: {auc_train_mean:.4f} (95% CI: {auc_train_lower:.4f}, {auc_train_upper:.4f})\")\n",
    "\n",
    "auc_scores_test = bootstrap_roc_auc(y_test, y_test_pred_proba)\n",
    "auc_test_mean = np.mean(auc_scores_test)\n",
    "auc_test_std = np.std(auc_scores_test)\n",
    "auc_test_lower = norm.ppf(0.025, loc=auc_test_mean, scale=auc_test_std)\n",
    "auc_test_upper = norm.ppf(0.975, loc=auc_test_mean, scale=auc_test_std)\n",
    "print(f\"Test AUC: {auc_test_mean:.4f} (95% CI: {auc_test_lower:.4f}, {auc_test_upper:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5626da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (python3.7)",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
