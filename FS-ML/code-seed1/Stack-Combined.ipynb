{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e81b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mutual_info_score, roc_curve, auc, confusion_matrix, classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2b819d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567424\n",
      "         Iterations 7\n",
      "TLR-SUVmax - univariate logistic regression:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Label   No. Observations:                  207\n",
      "Model:                          Logit   Df Residuals:                      205\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 03 Dec 2024   Pseudo R-squ.:                  0.1790\n",
      "Time:                        17:25:10   Log-Likelihood:                -117.46\n",
      "converged:                       True   LL-Null:                       -143.07\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.205e-13\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0477      0.172      0.278      0.781      -0.289       0.384\n",
      "TLR-SUVmax     1.5727      0.300      5.244      0.000       0.985       2.161\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658694\n",
      "         Iterations 8\n",
      "PSMATV - univariate logistic regression:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Label   No. Observations:                  207\n",
      "Model:                          Logit   Df Residuals:                      205\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 03 Dec 2024   Pseudo R-squ.:                 0.04699\n",
      "Time:                        17:25:10   Log-Likelihood:                -136.35\n",
      "converged:                       True   LL-Null:                       -143.07\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002454\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1148      0.193      0.594      0.552      -0.264       0.493\n",
      "PSMATV         2.2592      0.954      2.369      0.018       0.390       4.128\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679370\n",
      "         Iterations 4\n",
      "CTmean - univariate logistic regression:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Label   No. Observations:                  207\n",
      "Model:                          Logit   Df Residuals:                      205\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 03 Dec 2024   Pseudo R-squ.:                 0.01708\n",
      "Time:                        17:25:10   Log-Likelihood:                -140.63\n",
      "converged:                       True   LL-Null:                       -143.07\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02706\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1304      0.141     -0.925      0.355      -0.407       0.146\n",
      "CTmean         0.3171      0.148      2.141      0.032       0.027       0.607\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.673063\n",
      "         Iterations 5\n",
      "CTmin - univariate logistic regression:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Label   No. Observations:                  207\n",
      "Model:                          Logit   Df Residuals:                      205\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 03 Dec 2024   Pseudo R-squ.:                 0.02620\n",
      "Time:                        17:25:10   Log-Likelihood:                -139.32\n",
      "converged:                       True   LL-Null:                       -143.07\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.006178\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1756      0.145     -1.209      0.227      -0.460       0.109\n",
      "CTmin          0.4638      0.192      2.422      0.015       0.088       0.839\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537111\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537111\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "# read data (Baseline)\n",
    "train_data_Baseline = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\Baseline\\6-4ADASYN-1\\standardized\\train.csv')\n",
    "test_data_Baseline = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\Baseline\\6-4ADASYN-1\\standardized\\test.csv')\n",
    "\n",
    "# Selector --- univariate logistic regression\n",
    "significant_features_Baseline = []\n",
    "def perform_single_factor_analyses_and_select_features(train_df):\n",
    "    global significant_features_Baseline  \n",
    "    significant_features_Baseline = []  \n",
    "    num_features = len(train_df.columns) - 1  \n",
    "    for i in range(num_features):\n",
    "        feature_name = train_df.columns[i+1]\n",
    "        X = train_df[[feature_name]]\n",
    "        y = train_df['Label']\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.Logit(y, X).fit()\n",
    "        print(f\"{feature_name} - univariate logistic regression:\")\n",
    "        print(model.summary())\n",
    "        \n",
    "        if model.pvalues[1] < 0.05:\n",
    "            significant_features_Baseline.append(feature_name)\n",
    "            \n",
    "    return significant_features_Baseline\n",
    "\n",
    "selected_features_Baseline = perform_single_factor_analyses_and_select_features(train_data_Baseline)\n",
    "\n",
    "# Classifier --- multivariate logistic regression\n",
    "def build_multi_factor_model_Baseline(train_data_Baseline, test_data_Baseline, selected_features_Baseline):\n",
    "    X_train_Baseline = train_data_Baseline[selected_features_Baseline]\n",
    "    y_train_Baseline = train_data_Baseline['Label']\n",
    "    X_test_Baseline = test_data_Baseline[selected_features_Baseline]\n",
    "    y_test_Baseline = test_data_Baseline['Label']\n",
    "    \n",
    "    X_train_sm_Baseline = sm.add_constant(X_train_Baseline)\n",
    "    X_test_sm_Baseline = sm.add_constant(X_test_Baseline)\n",
    "    \n",
    "    model_Baseline = sm.Logit(y_train_Baseline, X_train_sm_Baseline)\n",
    "    result_Baseline = model_Baseline.fit()\n",
    "    \n",
    "    y_pred_probs_train_Baseline = result_Baseline.predict(X_train_sm_Baseline)  \n",
    "    y_pred_probs_test_Baseline = result_Baseline.predict(X_test_sm_Baseline)  \n",
    "    y_pred_train_Baseline = (y_pred_probs_train_Baseline > 0.5).astype(int)\n",
    "    y_pred_test_Baseline = (y_pred_probs_test_Baseline > 0.5).astype(int)\n",
    "    \n",
    "    return y_pred_probs_train_Baseline, y_pred_probs_test_Baseline\n",
    "    \n",
    "    train_fpr_Baseline, train_tpr_Baseline, _ = roc_curve(y_train_Baseline, y_pred_probs_train_Baseline)\n",
    "    test_fpr_Baseline, test_tpr_Baseline, _ = roc_curve(y_test_Baseline, y_pred_probs_test_Baseline)\n",
    "    \n",
    "    conf_matrix_train_Baseline = confusion_matrix(y_train_Baseline, y_pred_train_Baseline)\n",
    "    train_tn_Baseline, train_fp_Baseline, _, train_tp_Baseline = conf_matrix_train_Baseline.ravel()\n",
    "    train_specificity_Baseline = train_tn_Baseline / (train_tn_Baseline + train_fp_Baseline)\n",
    "    train_ppv_Baseline = train_tp_Baseline / (train_tp_Baseline + _)\n",
    "    train_npv_Baseline = train_tn_Baseline / (train_tn_Baseline + _)\n",
    "\n",
    "    conf_matrix_test_Baseline = confusion_matrix(y_test_Baseline, y_pred_test_Baseline)\n",
    "    test_tn_Baseline, test_fp_Baseline, _, test_tp_Baseline = conf_matrix_test_Baseline.ravel()\n",
    "    test_specificity_Baseline = test_tn_Baseline / (test_tn_Baseline + test_fp_Baseline)\n",
    "    test_ppv_Baseline = test_tp_Baseline / (test_tp_Baseline + _)\n",
    "    test_npv_Baseline = test_tn_Baseline / (test_tn_Baseline + _)\n",
    "\n",
    "    def calculate_auc_with_ci_Baseline(y_true, y_pred_probs, bootstrap_samples=1000):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_probs)\n",
    "        initial_auc_Baseline = auc(fpr, tpr)\n",
    "        aucs_Baseline = []\n",
    "        for _ in range(bootstrap_samples):\n",
    "            sample_indices = np.random.choice(len(y_pred_probs), len(y_pred_probs), replace=True)\n",
    "            sampled_probs = y_pred_probs[sample_indices]\n",
    "            fpr_sample, tpr_sample, _ = roc_curve(y_true[sample_indices], sampled_probs)\n",
    "            auc_sample = auc(fpr_sample, tpr_sample)\n",
    "            aucs_Baseline.append(auc_sample)\n",
    "        auc_mean_Baseline = np.mean(aucs_Baseline)\n",
    "        auc_low_Baseline, auc_high_Baseline = np.percentile(aucs_Baseline, [2.5, 97.5])\n",
    "        return auc_mean_Baseline, auc_low_Baseline, auc_high_Baseline\n",
    "    train_auc_mean_Baseline, train_auc_low_Baseline, train_auc_high_Baseline = calculate_auc_with_ci_Baseline(y_train_Baseline, y_pred_probs_train_Baseline)\n",
    "    test_auc_mean_Baseline, test_auc_low_Baseline, test_auc_high_Baseline = calculate_auc_with_ci_Baseline(y_test_Baseline, y_pred_probs_test_Baseline)\n",
    "    \n",
    "build_multi_factor_model_Baseline(train_data_Baseline, test_data_Baseline, selected_features_Baseline)\n",
    "y_pred_probs_train_Baseline, y_pred_probs_test_Baseline = build_multi_factor_model_Baseline(train_data_Baseline, test_data_Baseline, selected_features_Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2341e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 101.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features names: ['CT_wavelet.LLH_glcm_Idn', 'CT_wavelet.LHL_firstorder_Median', 'CT_original_shape_Elongation', 'CT_wavelet.LHL_glcm_MaximumProbability', 'CT_wavelet.LLL_glcm_Correlation', 'CT_log.sigma.1.mm.3D_firstorder_90Percentile', 'CT_wavelet.HLH_glcm_MCC', 'CT_wavelet.HHL_firstorder_Median', 'CT_wavelet.HHL_ngtdm_Contrast', 'CT_original_firstorder_10Percentile']\n",
      "Selected features names: ['CT_wavelet.LLH_glcm_Idn', 'CT_wavelet.LHL_firstorder_Median', 'CT_original_shape_Elongation', 'CT_wavelet.LHL_glcm_MaximumProbability', 'CT_wavelet.LLL_glcm_Correlation', 'CT_log.sigma.1.mm.3D_firstorder_90Percentile', 'CT_wavelet.HLH_glcm_MCC', 'CT_wavelet.HHL_firstorder_Median', 'CT_wavelet.HHL_ngtdm_Contrast', 'CT_original_firstorder_10Percentile']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "# Read data (CT)\n",
    "train_data_CT = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_CT_bin50\\6-4ADASYN-1\\train.csv')\n",
    "test_data_CT = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_CT_bin50\\6-4ADASYN-1\\test.csv')\n",
    "\n",
    "X_train_CT = train_data_CT.iloc[:, 1:]  \n",
    "y_train_CT = train_data_CT.iloc[:, 0]   \n",
    "X_test_CT = test_data_CT.iloc[:, 1:]  \n",
    "y_test_CT = test_data_CT.iloc[:, 0]\n",
    "\n",
    "# Feature Selector ---- MRMR\n",
    "try:\n",
    "    selected_features_CT = mrmr_classif(X=X_train_CT, y=y_train_CT, K=10, n_jobs=1)\n",
    "    print(\"Selected features names:\", selected_features_CT)\n",
    "\n",
    "    X_train_selected_top_ten_CT = X_train_CT[selected_features_CT]\n",
    "    X_test_selected_top_ten_CT = X_test_CT[selected_features_CT]\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "print(\"Selected features names:\", selected_features_CT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9315dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "# Read data (PET)\n",
    "### If the data is post-harmonized, no additional feature selection process is required.\n",
    "train_data_PET = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_PET1_bin0.25\\6-4ADASYN-1\\post-Combat\\mRMR\\train.csv')\n",
    "test_data_PET = pd.read_csv(r'C:\\Users\\37427\\Desktop\\github\\FS-ML\\RFs_PET1_bin0.25\\6-4ADASYN-1\\post-Combat\\mRMR\\test.csv')\n",
    "\n",
    "X_train_PET = train_data_PET.iloc[:, 1:]  \n",
    "y_train_PET = train_data_PET.iloc[:, 0]   \n",
    "X_test_PET = test_data_PET.iloc[:, 1:]   \n",
    "y_test_PET = test_data_PET.iloc[:, 0]    \n",
    "\n",
    "# Feature Selector ---- MRMR\n",
    "#try:\n",
    "#    selected_features_PET = mrmr_classif(X=X_train_PET, y=y_train_PET, K=10, n_jobs=1)\n",
    "#    print(\"Selected features names:\", selected_features_PET)\n",
    "\n",
    "#    X_train_selected_top_ten_PET = X_train_PET[selected_features_PET]\n",
    "#    X_test_selected_top_ten_PET = X_test_PET[selected_features_PET]\n",
    "#except Exception as e:\n",
    "#    print(\"An error occurred:\", e)\n",
    "\n",
    "#print(\"Selected features names:\", selected_features_PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b827a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Sensitivity (Cross-Validation_CT): 0.8144\n",
      "Specificity (Cross-Validation_CT): 0.7818\n",
      "PPV (Cross-Validation_CT): 0.7670\n",
      "NPV (Cross-Validation_CT): 0.8269\n",
      "Precision (Cross-Validation_CT): 0.7670\n",
      "Recall (Cross-Validation_CT): 0.8144\n",
      "F1 Score (Cross-Validation_CT): 0.7900\n",
      "Train Accuracy (Cross-Validation_CT): 0.7978\n",
      "Sensitivity (Test_CT): 0.6579\n",
      "Specificity (Test_CT): 0.7917\n",
      "PPV (Test_CT): 0.6250\n",
      "NPV (Test_CT): 0.8143\n",
      "Precision (Test_CT): 0.6250\n",
      "Recall (Test_CT): 0.6579\n",
      "F1 Score (Test_CT): 0.6410\n",
      "Test Accuracy_CT: 0.7455\n",
      "Cross-Validation AUC_CT: 0.8904 (95% CI: 0.8473, 0.9335)\n",
      "Test AUC_CT: 0.8141 (95% CI: 0.7296, 0.8987)\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "#Classifier (CT) --- Random Forest\n",
    "np.random.seed(0)\n",
    "param_grid_CT = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10],   \n",
    "    'min_samples_leaf': [1, 2, 4],    \n",
    "    'bootstrap': [True, False]          \n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "grid_search_CT = GridSearchCV(estimator=rf, param_grid=param_grid_CT, cv=5, scoring='accuracy')\n",
    "grid_search_CT.fit(X_train_selected_top_ten_CT, y_train_CT)\n",
    "print(\"Best parameters:\", grid_search_CT.best_params_)\n",
    "best_model_CT = grid_search_CT.best_estimator_\n",
    "\n",
    "y_train_pred_cv_CT = cross_val_predict(best_model_CT, X_train_selected_top_ten_CT, y_train_CT, cv=5)\n",
    "y_train_pred_proba_cv_CT = cross_val_predict(best_model_CT, X_train_selected_top_ten_CT, y_train_CT, cv=5, method='predict_proba')[:, 1]\n",
    "train_precision_cv_CT, train_recall_cv_CT, train_f1_cv_CT, _ = precision_recall_fscore_support(y_train_CT, y_train_pred_cv_CT, average='binary')\n",
    "y_test_pred_CT = best_model_CT.predict(X_test_selected_top_ten_CT)\n",
    "y_test_pred_proba_CT = best_model_CT.predict_proba(X_test_selected_top_ten_CT)[:, 1]\n",
    "test_precision_CT, test_recall_CT, test_f1_CT, _ = precision_recall_fscore_support(y_test_CT, y_test_pred_CT, average='binary')\n",
    "\n",
    "train_accuracy_cv_CT = cross_val_score(best_model_CT, X_train_selected_top_ten_CT, y_train_CT, cv=5, scoring='accuracy').mean()\n",
    "test_accuracy_CT = accuracy_score(y_test_CT, y_test_pred_CT)\n",
    "conf_mat_train_cv_CT = confusion_matrix(y_train_CT, y_train_pred_cv_CT)\n",
    "conf_mat_test_CT = confusion_matrix(y_test_CT, y_test_pred_CT)\n",
    "sensitivity_train_CT = conf_mat_train_cv_CT[1, 1] / (conf_mat_train_cv_CT[1, 1] + conf_mat_train_cv_CT[1, 0])  # TP / (TP + FN)\n",
    "sensitivity_test_CT = conf_mat_test_CT[1, 1] / (conf_mat_test_CT[1, 1] + conf_mat_test_CT[1, 0])  # TP / (TP + FN)\n",
    "specificity_train_CT = conf_mat_train_cv_CT[0, 0] / (conf_mat_train_cv_CT[0, 0] + conf_mat_train_cv_CT[0, 1])\n",
    "specificity_test_CT = conf_mat_test_CT[0, 0] / (conf_mat_test_CT[0, 0] + conf_mat_test_CT[0, 1])\n",
    "ppv_train_CT = conf_mat_train_cv_CT[1, 1] / (conf_mat_train_cv_CT[1, 1] + conf_mat_train_cv_CT[0, 1])\n",
    "npv_train_CT = conf_mat_train_cv_CT[0, 0] / (conf_mat_train_cv_CT[0, 0] + conf_mat_train_cv_CT[1, 0])\n",
    "ppv_test_CT = conf_mat_test_CT[1, 1] / (conf_mat_test_CT[1, 1] + conf_mat_test_CT[0, 1])\n",
    "npv_test_CT = conf_mat_test_CT[0, 0] / (conf_mat_test_CT[0, 0] + conf_mat_test_CT[1, 0])\n",
    "train_precision_CT = precision_score(y_train_CT, y_train_pred_cv_CT)\n",
    "test_precision_CT = precision_score(y_test_CT, y_test_pred_CT)\n",
    "train_recall_CT = recall_score(y_train_CT, y_train_pred_cv_CT)\n",
    "test_recall_CT = recall_score(y_test_CT, y_test_pred_CT)\n",
    "train_f1_CT = f1_score(y_train_CT, y_train_pred_cv_CT)\n",
    "test_f1_CT = f1_score(y_test_CT, y_test_pred_CT)\n",
    "print(f\"Sensitivity (Cross-Validation_CT): {sensitivity_train_CT:.4f}\")\n",
    "print(f\"Specificity (Cross-Validation_CT): {specificity_train_CT:.4f}\")\n",
    "print(f\"PPV (Cross-Validation_CT): {ppv_train_CT:.4f}\")\n",
    "print(f\"NPV (Cross-Validation_CT): {npv_train_CT:.4f}\")\n",
    "print(f\"Precision (Cross-Validation_CT): {train_precision_CT:.4f}\")\n",
    "print(f\"Recall (Cross-Validation_CT): {train_recall_CT:.4f}\")\n",
    "print(f\"F1 Score (Cross-Validation_CT): {train_f1_CT:.4f}\")\n",
    "print(f\"Train Accuracy (Cross-Validation_CT): {train_accuracy_cv_CT:.4f}\")\n",
    "print(f\"Sensitivity (Test_CT): {sensitivity_test_CT:.4f}\")\n",
    "print(f\"Specificity (Test_CT): {specificity_test_CT:.4f}\")\n",
    "print(f\"PPV (Test_CT): {ppv_test_CT:.4f}\")\n",
    "print(f\"NPV (Test_CT): {npv_test_CT:.4f}\")\n",
    "print(f\"Precision (Test_CT): {test_precision_CT:.4f}\")\n",
    "print(f\"Recall (Test_CT): {test_recall_CT:.4f}\")\n",
    "print(f\"F1 Score (Test_CT): {test_f1_CT:.4f}\")\n",
    "print(f\"Test Accuracy_CT: {test_accuracy_CT:.4f}\")\n",
    "\n",
    "fpr_train_CT, tpr_train_CT, _ = roc_curve(y_train_CT, y_train_pred_proba_cv_CT)\n",
    "fpr_test_CT, tpr_test_CT, _ = roc_curve(y_test_CT, y_test_pred_proba_CT)\n",
    "np.random.seed(0)\n",
    "def bootstrap_roc_auc(y_true, y_scores, n_bootstraps=1000):\n",
    "    auc_scores = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true), size=len(y_true))\n",
    "        auc_scores[i] = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "    return auc_scores\n",
    "\n",
    "auc_scores_train_CT = bootstrap_roc_auc(y_train_CT, y_train_pred_proba_cv_CT)\n",
    "auc_train_mean_CT = np.mean(auc_scores_train_CT)\n",
    "auc_train_std_CT = np.std(auc_scores_train_CT)\n",
    "auc_train_lower_CT = norm.ppf(0.025, loc=auc_train_mean_CT, scale=auc_train_std_CT)\n",
    "auc_train_upper_CT = norm.ppf(0.975, loc=auc_train_mean_CT, scale=auc_train_std_CT)\n",
    "print(f\"Cross-Validation AUC_CT: {auc_train_mean_CT:.4f} (95% CI: {auc_train_lower_CT:.4f}, {auc_train_upper_CT:.4f})\")\n",
    "\n",
    "auc_scores_test_CT = bootstrap_roc_auc(y_test_CT, y_test_pred_proba_CT)\n",
    "auc_test_mean_CT = np.mean(auc_scores_test_CT)\n",
    "auc_test_std_CT = np.std(auc_scores_test_CT)\n",
    "auc_test_lower_CT = norm.ppf(0.025, loc=auc_test_mean_CT, scale=auc_test_std_CT)\n",
    "auc_test_upper_CT = norm.ppf(0.975, loc=auc_test_mean_CT, scale=auc_test_std_CT)\n",
    "print(f\"Test AUC_CT: {auc_test_mean_CT:.4f} (95% CI: {auc_test_lower_CT:.4f}, {auc_test_upper_CT:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827e974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "Sensitivity (Cross-Validation_PET): 0.6701\n",
      "Specificity (Cross-Validation_PET): 0.7727\n",
      "PPV (Cross-Validation_PET): 0.7222\n",
      "NPV (Cross-Validation_PET): 0.7265\n",
      "Precision (Cross-Validation_PET): 0.7222\n",
      "Recall (Cross-Validation_PET): 0.6701\n",
      "F1 Score (Cross-Validation_PET): 0.6952\n",
      "Train Accuracy (Cross-Validation_PET): 0.7243\n",
      "Sensitivity (Test_PET): 0.6579\n",
      "Specificity (Test_PET): 0.8056\n",
      "PPV (Test_PET): 0.6410\n",
      "NPV (Test_PET): 0.8169\n",
      "Precision (Test_PET): 0.6410\n",
      "Recall (Test_PET): 0.6579\n",
      "F1 Score (Test_PET): 0.6494\n",
      "Test Accuracy_PET: 0.7545\n",
      "Cross-Validation AUC_PET: 0.7776 (95% CI: 0.7153, 0.8400)\n",
      "Test AUC_PET: 0.8605 (95% CI: 0.7957, 0.9254)\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality PET-CT stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "#Classifier (PET) --- Logistic Regression\n",
    "np.random.seed(0)\n",
    "param_grid_PET = {\n",
    "    'C': [0.1, 1.0, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [1000],\n",
    "    'tol': [1e-4]\n",
    "}\n",
    "logistic = LogisticRegression()\n",
    "grid_search_PET = GridSearchCV(estimator=logistic, param_grid=param_grid_PET, cv=5, scoring='accuracy')\n",
    "#grid_search_PET.fit(X_train_selected_top_ten_PET, y_train_PET)\n",
    "grid_search_PET.fit(X_train_PET, y_train_PET)\n",
    "print(\"Best parameters:\", grid_search_PET.best_params_)\n",
    "best_model_PET = grid_search_PET.best_estimator_\n",
    "\n",
    "#y_train_pred_cv_PET = cross_val_predict(best_model_PET, X_train_selected_top_ten_PET, y_train_PET, cv=5)\n",
    "y_train_pred_cv_PET = cross_val_predict(best_model_PET, X_train_PET, y_train_PET, cv=5)\n",
    "#y_train_pred_proba_cv_PET = cross_val_predict(best_model_PET, X_train_selected_top_ten_PET, y_train_PET, cv=5, method='predict_proba')[:, 1]\n",
    "y_train_pred_proba_cv_PET = cross_val_predict(best_model_PET, X_train_PET, y_train_PET, cv=5, method='predict_proba')[:, 1]\n",
    "train_precision_cv_PET, train_recall_cv_PET, train_f1_cv_PET, _ = precision_recall_fscore_support(y_train_PET, y_train_pred_cv_PET, average='binary')\n",
    "#y_test_pred_PET = best_model_PET.predict(X_test_selected_top_ten_PET)\n",
    "y_test_pred_PET = best_model_PET.predict(X_test_PET)\n",
    "#y_test_pred_proba_PET = best_model_PET.predict_proba(X_test_selected_top_ten_PET)[:, 1]\n",
    "y_test_pred_proba_PET = best_model_PET.predict_proba(X_test_PET)[:, 1]\n",
    "test_precision_PET, test_recall_PET, test_f1_PET, _ = precision_recall_fscore_support(y_test_PET, y_test_pred_PET, average='binary')\n",
    "\n",
    "#train_accuracy_cv_PET = cross_val_score(best_model_PET, X_train_selected_top_ten_PET, y_train_PET, cv=5, scoring='accuracy').mean()\n",
    "train_accuracy_cv_PET = cross_val_score(best_model_PET, X_train_PET, y_train_PET, cv=5, scoring='accuracy').mean()\n",
    "test_accuracy_PET = accuracy_score(y_test_PET, y_test_pred_PET)\n",
    "conf_mat_train_cv_PET = confusion_matrix(y_train_PET, y_train_pred_cv_PET)\n",
    "conf_mat_test_PET = confusion_matrix(y_test_PET, y_test_pred_PET)\n",
    "sensitivity_train_PET = conf_mat_train_cv_PET[1, 1] / (conf_mat_train_cv_PET[1, 1] + conf_mat_train_cv_PET[1, 0])  # TP / (TP + FN)\n",
    "sensitivity_test_PET = conf_mat_test_PET[1, 1] / (conf_mat_test_PET[1, 1] + conf_mat_test_PET[1, 0])  # TP / (TP + FN)\n",
    "specificity_train_PET = conf_mat_train_cv_PET[0, 0] / (conf_mat_train_cv_PET[0, 0] + conf_mat_train_cv_PET[0, 1])\n",
    "specificity_test_PET = conf_mat_test_PET[0, 0] / (conf_mat_test_PET[0, 0] + conf_mat_test_PET[0, 1])\n",
    "ppv_train_PET = conf_mat_train_cv_PET[1, 1] / (conf_mat_train_cv_PET[1, 1] + conf_mat_train_cv_PET[0, 1])\n",
    "npv_train_PET = conf_mat_train_cv_PET[0, 0] / (conf_mat_train_cv_PET[0, 0] + conf_mat_train_cv_PET[1, 0])\n",
    "ppv_test_PET = conf_mat_test_PET[1, 1] / (conf_mat_test_PET[1, 1] + conf_mat_test_PET[0, 1])\n",
    "npv_test_PET = conf_mat_test_PET[0, 0] / (conf_mat_test_PET[0, 0] + conf_mat_test_PET[1, 0])\n",
    "train_precision_PET = precision_score(y_train_PET, y_train_pred_cv_PET)\n",
    "test_precision_PET = precision_score(y_test_PET, y_test_pred_PET)\n",
    "train_recall_PET = recall_score(y_train_PET, y_train_pred_cv_PET)\n",
    "test_recall_PET = recall_score(y_test_PET, y_test_pred_PET)\n",
    "train_f1_PET = f1_score(y_train_PET, y_train_pred_cv_PET)\n",
    "test_f1_PET = f1_score(y_test_PET, y_test_pred_PET)\n",
    "print(f\"Sensitivity (Cross-Validation_PET): {sensitivity_train_PET:.4f}\")\n",
    "print(f\"Specificity (Cross-Validation_PET): {specificity_train_PET:.4f}\")\n",
    "print(f\"PPV (Cross-Validation_PET): {ppv_train_PET:.4f}\")\n",
    "print(f\"NPV (Cross-Validation_PET): {npv_train_PET:.4f}\")\n",
    "print(f\"Precision (Cross-Validation_PET): {train_precision_PET:.4f}\")\n",
    "print(f\"Recall (Cross-Validation_PET): {train_recall_PET:.4f}\")\n",
    "print(f\"F1 Score (Cross-Validation_PET): {train_f1_PET:.4f}\")\n",
    "print(f\"Train Accuracy (Cross-Validation_PET): {train_accuracy_cv_PET:.4f}\")\n",
    "print(f\"Sensitivity (Test_PET): {sensitivity_test_PET:.4f}\")\n",
    "print(f\"Specificity (Test_PET): {specificity_test_PET:.4f}\")\n",
    "print(f\"PPV (Test_PET): {ppv_test_PET:.4f}\")\n",
    "print(f\"NPV (Test_PET): {npv_test_PET:.4f}\")\n",
    "print(f\"Precision (Test_PET): {test_precision_PET:.4f}\")\n",
    "print(f\"Recall (Test_PET): {test_recall_PET:.4f}\")\n",
    "print(f\"F1 Score (Test_PET): {test_f1_PET:.4f}\")\n",
    "print(f\"Test Accuracy_PET: {test_accuracy_PET:.4f}\")\n",
    "\n",
    "fpr_train_PET, tpr_train_PET, _ = roc_curve(y_train_PET, y_train_pred_proba_cv_PET)\n",
    "fpr_test_PET, tpr_test_PET, _ = roc_curve(y_test_PET, y_test_pred_proba_PET)\n",
    "np.random.seed(0)\n",
    "def bootstrap_roc_auc(y_true, y_scores, n_bootstraps=1000):\n",
    "    auc_scores = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true), size=len(y_true))\n",
    "        auc_scores[i] = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "    return auc_scores\n",
    "\n",
    "auc_scores_train_PET = bootstrap_roc_auc(y_train_PET, y_train_pred_proba_cv_PET)\n",
    "auc_train_mean_PET = np.mean(auc_scores_train_PET)\n",
    "auc_train_std_PET = np.std(auc_scores_train_PET)\n",
    "auc_train_lower_PET = norm.ppf(0.025, loc=auc_train_mean_PET, scale=auc_train_std_PET)\n",
    "auc_train_upper_PET = norm.ppf(0.975, loc=auc_train_mean_PET, scale=auc_train_std_PET)\n",
    "print(f\"Cross-Validation AUC_PET: {auc_train_mean_PET:.4f} (95% CI: {auc_train_lower_PET:.4f}, {auc_train_upper_PET:.4f})\")\n",
    "\n",
    "auc_scores_test_PET = bootstrap_roc_auc(y_test_PET, y_test_pred_proba_PET)\n",
    "auc_test_mean_PET = np.mean(auc_scores_test_PET)\n",
    "auc_test_std_PET = np.std(auc_scores_test_PET)\n",
    "auc_test_lower_PET = norm.ppf(0.025, loc=auc_test_mean_PET, scale=auc_test_std_PET)\n",
    "auc_test_upper_PET = norm.ppf(0.975, loc=auc_test_mean_PET, scale=auc_test_std_PET)\n",
    "print(f\"Test AUC_PET: {auc_test_mean_PET:.4f} (95% CI: {auc_test_lower_PET:.4f}, {auc_test_upper_PET:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1249207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression Meta-learner: {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "Sensitivity (Cross-Validation Meta-learner): 0.8351\n",
      "Specificity (Cross-Validation Meta-learner): 0.8818\n",
      "PPV (Cross-Validation Meta-learner): 0.8617\n",
      "NPV (Cross-Validation Meta-learner): 0.8584\n",
      "Precision (Cross-Validation Meta-learner): 0.8617\n",
      "Recall (Cross-Validation Meta-learner): 0.8351\n",
      "F1 Score (Cross-Validation Meta-learner): 0.8482\n",
      "Train Accuracy (Cross-Validation  Meta-learner): 0.8600\n",
      "Sensitivity (Test Meta-learner): 0.7368\n",
      "Specificity (Test Meta-learner): 0.8750\n",
      "PPV (Test Meta-learner): 0.7568\n",
      "NPV (Test Meta-learner): 0.8630\n",
      "Precision (Test Meta-learner): 0.7568\n",
      "Recall (Test Meta-learner): 0.7368\n",
      "F1 Score (Test Meta-learner): 0.7467\n",
      "Test Accuracy (Test Meta-learner): 0.8273\n",
      "Meta-learner Cross-Validation AUC: 0.9191 (95% CI: 0.8816, 0.9566)\n",
      "Meta-learner Test AUC: 0.8754 (95% CI: 0.8013, 0.9495)\n"
     ]
    }
   ],
   "source": [
    "### One example of dual-modality Combined stacking model. \n",
    "### Please adjust the code based on specific optimal feature selection and ML methods (refer to other single-modality model code format).\n",
    "#Classifier (Meta) --- Logistic Regression/SVM\n",
    "X_train_meta_features = np.column_stack([\n",
    "    y_pred_probs_train_Baseline,  \n",
    "    y_train_pred_proba_cv_CT,      \n",
    "    y_train_pred_proba_cv_PET    \n",
    "])\n",
    "\n",
    "X_test_meta_features = np.column_stack([\n",
    "    y_pred_probs_test_Baseline,   \n",
    "    y_test_pred_proba_CT,         \n",
    "    y_test_pred_proba_PET         \n",
    "])\n",
    "\n",
    "np.random.seed(0)\n",
    "lr = LogisticRegression()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [1000],\n",
    "    'tol': [1e-4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_meta_features, y_train_CT)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters for Logistic Regression Meta-learner:\", best_params)\n",
    "\n",
    "best_meta_model = grid_search.best_estimator_\n",
    "y_train_meta_pred = cross_val_predict(best_meta_model, X_train_meta_features, y_train_CT, cv=5)\n",
    "y_test_meta_pred = best_meta_model.predict(X_test_meta_features)\n",
    "y_train_meta_pred_proba = cross_val_predict(best_meta_model, X_train_meta_features, y_train_CT, cv=5, method='predict_proba')[:, 1]\n",
    "y_test_meta_pred_proba = best_meta_model.predict_proba(X_test_meta_features)[:, 1]\n",
    "\n",
    "train_accuracy_meta = cross_val_score(best_meta_model, X_train_meta_features, y_train_CT, cv=5, scoring='accuracy').mean()\n",
    "test_accuracy_meta = accuracy_score(y_test_CT, y_test_meta_pred)\n",
    "train_precision_meta, train_recall_meta, train_f1_meta, _ = precision_recall_fscore_support(y_train_CT, y_train_meta_pred, average='binary')\n",
    "test_precision_meta, test_recall_meta, test_f1_meta, _ = precision_recall_fscore_support(y_test_CT, y_test_meta_pred, average='binary')\n",
    "\n",
    "def calculate_additional_metrics(y_true, y_pred, y_proba):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])  # TP / (TP + FN)\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # TN / (TN + FP)\n",
    "    ppv = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])  # TP / (TP + FP)\n",
    "    npv = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[1, 0])  # TN / (TN + FN)\n",
    "    return sensitivity, specificity, ppv, npv, conf_matrix\n",
    "\n",
    "sensitivity_train_meta, train_specificity, train_ppv, train_npv, conf_mat_train_meta = calculate_additional_metrics(y_train_CT, y_train_meta_pred, y_train_meta_pred_proba)\n",
    "sensitivity_test_meta, test_specificity, test_ppv, test_npv, conf_mat_test_meta = calculate_additional_metrics(y_test_CT, y_test_meta_pred, y_test_meta_pred_proba)\n",
    "\n",
    "print(f\"Sensitivity (Cross-Validation Meta-learner): {sensitivity_train_meta:.4f}\")\n",
    "print(f\"Specificity (Cross-Validation Meta-learner): {train_specificity:.4f}\")\n",
    "print(f\"PPV (Cross-Validation Meta-learner): {train_ppv:.4f}\")\n",
    "print(f\"NPV (Cross-Validation Meta-learner): {train_npv:.4f}\")\n",
    "print(f\"Precision (Cross-Validation Meta-learner): {train_precision_meta:.4f}\")\n",
    "print(f\"Recall (Cross-Validation Meta-learner): {train_recall_meta:.4f}\")\n",
    "print(f\"F1 Score (Cross-Validation Meta-learner): {train_f1_meta:.4f}\")\n",
    "print(f\"Train Accuracy (Cross-Validation  Meta-learner): {train_accuracy_meta:.4f}\")\n",
    "print(f\"Sensitivity (Test Meta-learner): {sensitivity_test_meta:.4f}\")\n",
    "print(f\"Specificity (Test Meta-learner): {test_specificity:.4f}\")\n",
    "print(f\"PPV (Test Meta-learner): {test_ppv:.4f}\")\n",
    "print(f\"NPV (Test Meta-learner): {test_npv:.4f}\")\n",
    "print(f\"Precision (Test Meta-learner): {test_precision_meta:.4f}\")\n",
    "print(f\"Recall (Test Meta-learner): {test_recall_meta:.4f}\")\n",
    "print(f\"F1 Score (Test Meta-learner): {test_f1_meta:.4f}\")\n",
    "print(f\"Test Accuracy (Test Meta-learner): {test_accuracy_meta:.4f}\")\n",
    "\n",
    "np.random.seed(0)\n",
    "def bootstrap_roc_auc(y_true, y_scores, n_bootstraps=1000):\n",
    "    auc_scores = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true), size=len(y_true))\n",
    "        auc_scores[i] = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "    return auc_scores\n",
    "\n",
    "fpr_train_meta, tpr_train_meta, _ = roc_curve(y_train_CT, y_train_meta_pred_proba)\n",
    "fpr_test_meta, tpr_test_meta, _ = roc_curve(y_test_CT, y_test_meta_pred_proba)\n",
    "auc_scores_train_meta = bootstrap_roc_auc(y_train_CT, y_train_meta_pred_proba)\n",
    "auc_scores_test_meta = bootstrap_roc_auc(y_test_CT, y_test_meta_pred_proba)\n",
    "auc_train_mean_meta = np.mean(auc_scores_train_meta)\n",
    "auc_train_std_meta = np.std(auc_scores_train_meta)\n",
    "auc_test_mean_meta = np.mean(auc_scores_test_meta)\n",
    "auc_test_std_meta = np.std(auc_scores_test_meta)\n",
    "auc_train_lower_meta = norm.ppf(0.025, loc=auc_train_mean_meta, scale=auc_train_std_meta)\n",
    "auc_train_upper_meta = norm.ppf(0.975, loc=auc_train_mean_meta, scale=auc_train_std_meta)\n",
    "auc_test_lower_meta = norm.ppf(0.025, loc=auc_test_mean_meta, scale=auc_test_std_meta)\n",
    "auc_test_upper_meta = norm.ppf(0.975, loc=auc_test_mean_meta, scale=auc_test_std_meta)\n",
    "print(f\"Meta-learner Cross-Validation AUC: {auc_train_mean_meta:.4f} (95% CI: {auc_train_lower_meta:.4f}, {auc_train_upper_meta:.4f})\")\n",
    "print(f\"Meta-learner Test AUC: {auc_test_mean_meta:.4f} (95% CI: {auc_test_lower_meta:.4f}, {auc_test_upper_meta:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd45f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (python3.7)",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
